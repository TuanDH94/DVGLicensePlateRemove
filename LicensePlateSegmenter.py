import cv2
import numpy as np
import tensorflow as tf
import json
import utils_segment.Utility as Utility
import utils_segment.config as config
import utils_segment.Transformation as Transformation
import utils_segment.ContourFilter as cf
import datetime
import inspect
import os
from utils_segment.Model import CNNModel
from skimage import util
import multiprocessing

#
def find_contours(raw, im, limit):
    contours, _ = cv2.findContours(im, 1, 1)
    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:limit]
    return contours


class LicensePlateSegmenter:
    def __init__(self, tracking):
        self.tracking = tracking
        classpath = inspect.getfile(self.__class__)
        classpath = os.path.dirname(classpath)
        self.graph = tf.Graph()
        with self.graph.as_default() as graph_default:
            self.BGR_Classifier = CNNModel(config.char_height, config.char_width, 3, num_classes=2)
            self.load_model(bgr_model_path=classpath + '/resources/color_models/plate_character_detect_trained.ckpt-10000',
                        binary_model_path=classpath + '/resources/binary_models/plate_character_detect_trained.ckpt-5000')
        self.contours = []
        self.boxs = []

    def load_model(self, bgr_model_path, binary_model_path):
        self.BGR_Classifier.load_model(bgr_model_path, self.tracking)

    def find_character_contours(self, image):
        im = np.copy(image)
        im_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        thresholds = Utility.produce_thresholds(im_gray)
        height, _, _ = image.shape
        inputs = []
        inv_inputs = []

        for threshold in thresholds:
            contours = find_contours(im, threshold, 200)
            for i in range(len(contours)):
                cnt = contours[i]
                min_rect = cv2.minAreaRect(cnt)
                x_y, w_h, a = min_rect
                _, y = x_y
                max_size = max(w_h)
                if(max_size > config.min_size_contours and max_size < config.max_size_contours): #and y > height / 2 - 150):
                    box = cv2.boxPoints(min_rect)
                    box = np.int0(box)
                    # extract image generated by contour
                    warped = Transformation.four_points_transform(im, np.reshape(box, [4, 2]))
                    warped = cv2.resize(warped, dsize=(config.char_width, config.char_height), interpolation=cv2.INTER_CUBIC)
                    x = np.array(warped)
                    x = np.reshape(x, [config.char_height * config.char_width * 3])
                    inputs.append(x)
                    inv_inputs.append(util.invert(x))
                    self.boxs.append(box)
                    self.contours.append(cnt)

        inputs = Utility.list_to_numpy(inputs)
        inv_inputs = Utility.list_to_numpy(inv_inputs)
        #-------------------
        predicts = self.BGR_Classifier.predict(inputs)
        inv_predicts = self.BGR_Classifier.predict(inv_inputs)
        return predicts, inv_predicts

    def recognize_contours_in_plate(self, image):
        self.contours = []
        predicts, inv_predicts = self.find_character_contours(image)
        valid_contours = []
        if self.tracking:
            print('total character contours is {}'.format(len(predicts)))
        for i in range(len(predicts)):
            predict = predicts[i]
            label, score = np.argmax(predict), np.amax(predict)

            if (label == 1) and (score > config.min_score_classify):
                valid_contours.append(self.contours[i])

            inv_predict = inv_predicts[i]
            inv_label, inv_score = np.argmax(inv_predict), np.amax(inv_predict)

            if (inv_label == 1) and (inv_score > config.min_score_classify):
                valid_contours.append(self.contours[i])
        return valid_contours

    def seg_plate(self, image):
        ts = datetime.datetime.now().timestamp()
        with self.graph.as_default() as graph_default:
            contours = self.recognize_contours_in_plate(image)
            if self.tracking:
                print('recognize contours in plate in {} s'.format(datetime.datetime.now().timestamp() - ts))
            ts = datetime.datetime.now().timestamp()
            contours = cf.filter_by_box_size(contours, image)
            if self.tracking:
                print('filter contours in plate in {} s'.format(datetime.datetime.now().timestamp() - ts))
            ts = datetime.datetime.now().timestamp()
            out_img, result = Utility.inpaint(image, contours, self.tracking)
            if self.tracking:
                print('inpaint image in {} s'.format(datetime.datetime.now().timestamp() - ts))
            ts = datetime.datetime.now().timestamp()
            return out_img, result
        # return image


if __name__ == '__main__':
    path = 'E:\\ImageData\\colordata\\yolo_img'
    output_path = 'E:\\Source\\LicensePlateRecognition\\data\\output_test\\'
    numThread = multiprocessing.cpu_count()
    numThread = max(numThread, 16)
    sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=numThread))
    # path = 'E:/Untitled.png'
    # img = cv2.resize(img, dsize=(3*width, 3*height))
    plate_localizor = LicensePlateSegmenter(True)
    images = os.listdir(path)
    for image in images:
        image_path = os.path.join(path, image)
        img = cv2.imread(image_path)
        height, width, _ = img.shape
        out_img, result = plate_localizor.seg_plate(img)
        print(json.dumps(result, sort_keys=True, indent=4))
        cv2.imwrite(os.path.join(output_path, image),out_img)